{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\markt\\anaconda3\\envs\\metaverse_museum\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from query_based_search import Prompt_exhibition_generator\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\markt\\anaconda3\\envs\\metaverse_museum\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9368604]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = 'Van Gogh'\n",
    "s2 = 'Vincent van Gogh'\n",
    "embeddings1 = model.encode(s1, convert_to_tensor=True).cpu()\n",
    "embeddings2 = model.encode(s2, convert_to_tensor=True).cpu()\n",
    "cosine_similarity([embeddings1], [embeddings2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5578123]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = 'peaceful'\n",
    "s2 = 'serene'\n",
    "embeddings1 = model.encode(s1, convert_to_tensor=True).cpu()\n",
    "embeddings2 = model.encode(s2, convert_to_tensor=True).cpu()\n",
    "cosine_similarity([embeddings1], [embeddings2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6415447]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = 'Self-Portrait'\n",
    "s2 = 'Self-Portrait with a Straw Hat (obverse: The Potato Peeler)'\n",
    "embeddings1 = model.encode(s1, convert_to_tensor=True).cpu()\n",
    "embeddings2 = model.encode(s2, convert_to_tensor=True).cpu()\n",
    "cosine_similarity([embeddings1], [embeddings2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine_similarity([[1, 0, -1]], [[1,-1, -2]])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12432, 34)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\markt\\anaconda3\\envs\\metaverse_museum\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "c:\\Users\\markt\\anaconda3\\envs\\metaverse_museum\\Lib\\site-packages\\open_clip\\factory.py:129: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=map_location)\n"
     ]
    }
   ],
   "source": [
    "agent = Prompt_exhibition_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Tag extraction time: 0.684149980545044\n",
      "***Parse time: 0.40509629249572754\n",
      "***Total time taken to parse the prompt: 1.0892462730407715 seconds\n",
      "***Total time taken to search: 0.45961809158325195 seconds\n",
      "***Total time taken to filter the results: 20.521631002426147 seconds\n",
      "Successfully filtered the results based on tags and artists\n",
      "**** Getting embeddings of descriptions...\n",
      "Loading embeddings from file...\n",
      "**** Getting embeddings of descriptions done. Time taken: 0.006509542465209961 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Metaverse_Museum\\AI-Curators\\prompt_based_exhibition\\exhibition_curator.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.description_embeddings = torch.load(r'D:\\Metaverse_Museum\\AI-Curators\\data\\description_embeddings.pt')\n",
      "d:\\Metaverse_Museum\\AI-Curators\\prompt_based_exhibition\\exhibition_curator.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  recommendation_df.loc[:,'cluster_label'] = cluster_assignment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Total time taken to curate the exhibitions: 9.642972707748413 seconds\n",
      "Image saved as D:\\Metaverse_Museum\\AI-Curators\\prompt_based_exhibition\\output\\I want to see Van Gogh's use of color\\Exhibition_0.jpg\n",
      "Image saved as D:\\Metaverse_Museum\\AI-Curators\\prompt_based_exhibition\\output\\I want to see Van Gogh's use of color\\Exhibition_1.jpg\n",
      "***Total time taken to generate the exhibition: 45.867408752441406 seconds\n"
     ]
    }
   ],
   "source": [
    "agent.generate_exhibition(\"I want to see Van Gogh's use of color\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Tag extraction time: 0.7548065185546875\n",
      "***Parse time: 0.4632742404937744\n",
      "***Total time taken to parse the prompt: 1.218080759048462 seconds\n",
      "***Total time taken to search: 0.33702540397644043 seconds\n",
      "***Total time taken to filter the results: 16.078916788101196 seconds\n",
      "Successfully filtered the results based on tags and artists\n",
      "**** Getting embeddings of descriptions...\n",
      "Loading embeddings from file...\n",
      "**** Getting embeddings of descriptions done. Time taken: 0.008946895599365234 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Metaverse_Museum\\AI-Curators\\prompt_based_exhibition\\exhibition_curator.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.description_embeddings = torch.load(r'D:\\Metaverse_Museum\\AI-Curators\\data\\description_embeddings.pt')\n",
      "d:\\Metaverse_Museum\\AI-Curators\\prompt_based_exhibition\\exhibition_curator.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  recommendation_df.loc[:,'cluster_label'] = cluster_assignment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Total time taken to curate the exhibitions: 30.05069851875305 seconds\n",
      "Image saved as D:\\Metaverse_Museum\\AI-Curators\\prompt_based_exhibition\\output\\I want to see loneliness and depression\\Exhibition_0.jpg\n",
      "Image saved as D:\\Metaverse_Museum\\AI-Curators\\prompt_based_exhibition\\output\\I want to see loneliness and depression\\Exhibition_1.jpg\n",
      "Image saved as D:\\Metaverse_Museum\\AI-Curators\\prompt_based_exhibition\\output\\I want to see loneliness and depression\\Exhibition_2.jpg\n",
      "Image saved as D:\\Metaverse_Museum\\AI-Curators\\prompt_based_exhibition\\output\\I want to see loneliness and depression\\Exhibition_3.jpg\n",
      "Image saved as D:\\Metaverse_Museum\\AI-Curators\\prompt_based_exhibition\\output\\I want to see loneliness and depression\\Exhibition_4.jpg\n",
      "***Total time taken to generate the exhibition: 69.42788553237915 seconds\n"
     ]
    }
   ],
   "source": [
    "agent.generate_exhibition(\"I want to see loneliness and depression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metaverse_museum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
